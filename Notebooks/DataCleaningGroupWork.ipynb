{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XzGFitQl60K"
   },
   "source": [
    "# Data Cleaning with Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tAUAu98l-E6"
   },
   "source": [
    "## 1. Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdqLGpdH_867"
   },
   "source": [
    "#### <font color=\"blue\">Pre-requisites</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tzG_vFPsAF9H"
   },
   "outputs": [],
   "source": [
    "# Pre-requisite 1\n",
    "# ---\n",
    "# Importing pandas library\n",
    "# ---\n",
    "# -> This is a data analysis and manipulation library with Python.\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Gxs3j_OJQ7my"
   },
   "outputs": [],
   "source": [
    "# Pre-requisite 2\n",
    "# ---\n",
    "# Importing the numpy library\n",
    "# -> This is a library for scientific computing with Python.\n",
    "# -> It simply allows us to perfom complex mathematical operations.\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o39LEL0PmKJa"
   },
   "source": [
    "#### <font color=\"blue\">Tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMXTATeJmOGX"
   },
   "source": [
    "##### <font color=\"blue\">Task 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "Ql23JRMAlvv2",
    "outputId": "9477494f-4fe5-43f5-b26c-81497d37421d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>ACCOUNT A</th>\n",
       "      <th>ACCOUNT B</th>\n",
       "      <th>TOTAL ACCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adi Dako</td>\n",
       "      <td>LISBON</td>\n",
       "      <td>PORTUGAL</td>\n",
       "      <td>56</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>4340</td>\n",
       "      <td>6730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Paul</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>62</td>\n",
       "      <td>165.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>34334</td>\n",
       "      <td>38834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cindy Jules</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>48</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5504</td>\n",
       "      <td>8949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arthur Kegels</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td>59</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4344.0</td>\n",
       "      <td>8999</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Freya Bismark</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>GERMANYY</td>\n",
       "      <td>53</td>\n",
       "      <td>126.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>19000</td>\n",
       "      <td>26000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NAME        CITY         COUNTRY  HEIGHT  WEIGHT  ACCOUNT A  \\\n",
       "0          Adi Dako   LISBON       PORTUGAL           56   132.0     2390.0   \n",
       "1          John Paul   LONDON     UNITED KINGDOM      62   165.0     4500.0   \n",
       "2        Cindy Jules   Stockholm          Sweden      48   117.0        NaN   \n",
       "3      Arthur Kegels    BRUSSELS         BELGIUM      59   121.0     4344.0   \n",
       "4      Freya Bismark      Berlin        GERMANYY      53   126.0     7000.0   \n",
       "\n",
       "   ACCOUNT B  TOTAL ACCOUNT  \n",
       "0       4340           6730  \n",
       "1      34334          38834  \n",
       "2       5504           8949  \n",
       "3       8999            300  \n",
       "4      19000          26000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1\n",
    "# ---\n",
    "# Renaming column names\n",
    "# ---\n",
    "# Dataset url = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "\n",
    "# Reading our dataset from the url\n",
    "# ---\n",
    "# We also specify the character ; as our separator\n",
    "# ---\n",
    "#\n",
    "df = pd.read_csv('http://bit.ly/DataCleaningDataset', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "tjbZr_6MXhLb",
    "outputId": "60486c34-e623-47e8-9c7b-73cfdb14483b"
   },
   "outputs": [],
   "source": [
    "# Task 1a\n",
    "# ---\n",
    "# In this task, we will be renaming our columns, if we have many column names.\n",
    "# We will use the str.strip(), str.lower(), str.replace() functions\n",
    "# to ensure that our column names are in lowercase format that easily can work with.\n",
    "# ---\n",
    "# str.strip() - We use this function to remove leading and trailing characters.\n",
    "# str.lower() - This function converts all characters to lowercase\n",
    "# str.replace() - This functions is used replace text with some other text.\n",
    "# ---\n",
    "#\n",
    "\n",
    "# Then preview our dataframe\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VcZ63_4lWDRG",
    "outputId": "cf551ba6-6396-4f65-df37-7340d43dfd23"
   },
   "outputs": [],
   "source": [
    "# Task 1b\n",
    "# ---\n",
    "# Alternatively we can rename column names in a dataframe manually by\n",
    "# specifying the column names that we would like to have.\n",
    "# Something to note is that this method becomes cumbersome when the no. of variables/features increase.\n",
    "# ---\n",
    "#\n",
    "\n",
    "# We will reload our dataset again for this task and create a new dataframe.\n",
    "# ---\n",
    "#\n",
    "df2 = pd.read_csv('http://bit.ly/DataCleaningDataset', sep = ';')\n",
    "\n",
    "# We then specify our columns names, store them in a list, then afterwards\n",
    "# assign the list to the column labels. By doing this, we replace the original\n",
    "# columns with our new column names stored in the list.\n",
    "# ---\n",
    "#\n",
    "\n",
    "# We then preview our dataframe as shown to confirm our changes\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59SR9Kap7gMj"
   },
   "source": [
    "##### <font color=\"blue\">Task 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7g_2_fG1md0X",
    "outputId": "03a93784-4e28-4ed6-fc9c-9a32ea1d7db2"
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# ---\n",
    "# During standardisation, we can also perform string conversion.\n",
    "# In this task, we will convert the values of the column city to lower case values.\n",
    "# From the previous task 1, we can see that the city column/feature has values\n",
    "# with Upppercase and Sentense case values.\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "\n",
    "# Lets convert the city column to comprise of only lowercase characters\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCk6jJA-7cpm"
   },
   "source": [
    "##### <font color=\"blue\">Task 3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F8bgFBh2JAs3"
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# ---\n",
    "# We now perform types of conversion that we would want i.e. metric conversion.\n",
    "# In this task, we convert our height values to centimeters having in mind\n",
    "# that 1 inch = 2.54 cm.\n",
    "# ---\n",
    "# Dataset url = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "#\n",
    "\n",
    "# We perform our conversion across the column that we would want\n",
    "# then replace the column with the outcome of our conversion.\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F76wMqtH7Z6W"
   },
   "source": [
    "##### <font color=\"blue\">Task 4</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l7xqz-EHilp9"
   },
   "outputs": [],
   "source": [
    "# Task 4\n",
    "# ---\n",
    "# We can also perform other types of conversion such as datatype conversion \n",
    "# ---\n",
    "\n",
    "\n",
    "# Let's first determine the column/feature datatypes\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MVwcfVsfjW7G"
   },
   "outputs": [],
   "source": [
    "# We then perform a conversion by converting our column/feature (height)\n",
    "# through the use of the apply() function, passing the numerical\n",
    "# type (integer) provided by numpy\n",
    "# To get an understanding of other datatypes provided by numpy we can visit:\n",
    "# https://docs.scipy.org/doc/numpy/user/basics.types.html\n",
    "# ---\n",
    "# Other\n",
    "# ---\n",
    "#\n",
    "\n",
    "\n",
    "# Let's now check whether our conversion happened by checking our updated datatypes.\n",
    "# We want to see whether height feature was converted from float to integer.\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Pkj4GEXZR6Ll"
   },
   "outputs": [],
   "source": [
    "# We can also refer to our previous values of the height feature in task 2,\n",
    "# and we will see that our height values now only comprise of integers.\n",
    "# Let's now inspect and see whether our changes took place.\n",
    "# We will sample 5 records from our dataset. \n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWcy51lCOuTv"
   },
   "source": [
    "## 2. Syntax Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONPG_rNpOuT8"
   },
   "source": [
    "#### <font color=\"blue\">Tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBVRXQvY7WEB"
   },
   "source": [
    "##### <font color=\"blue\">Task 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6JgjmQlAOuUA"
   },
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# ---\n",
    "# While performing our analysis, we can get to a point where we need to\n",
    "# fix spelling mistakes or typos. \n",
    "# ---\n",
    "# Dataset url = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "\n",
    "# Let's replacing any value \"GERMANYY\" with the correct value \"GERMANY\".\n",
    "# We use the string replace() function to perform our operation as shown.\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZXm4a9V7VFq"
   },
   "source": [
    "##### <font color=\"blue\">Task 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cViv8asNOuUM"
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# ---\n",
    "# We can also decide to strip or remove leading spaces (space infront)\n",
    "# and trailing spaces (spaces at the end) in our datset by using the\n",
    "# string strip() function covered in this example.\n",
    "# ---\n",
    "# Dataset = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "\n",
    "# We first load our dataframe column with the intention to observe leading\n",
    "# and trailing spaces in the city column\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "u6hu9lJXnpPs"
   },
   "outputs": [],
   "source": [
    "# Then later we strip the leading and trailing spaces and lastly\n",
    "# confirm our changes by previewing the city column\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebaricL9O20B"
   },
   "source": [
    "## 3. Irrelevant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWZ0GCbCO20L"
   },
   "source": [
    "#### <font color=\"blue\">Tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjflp2aF7SUB"
   },
   "source": [
    "##### <font color=\"blue\">Task 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cTzUuFAyO20Q"
   },
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# ---\n",
    "# We can also delete/drop irrelevant columns/features.\n",
    "# By irrelevant we mean dataset features/columns that we don't need\n",
    "# to answer a research question.\n",
    "# ---\n",
    "# Dataset url = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2oiYYzezq4Wr"
   },
   "outputs": [],
   "source": [
    "# Deleting an Irrelevant Column i.e. if we don't require the column city\n",
    "# to answer our research question.\n",
    "# ---\n",
    "# While dropping/deleting those two columns:\n",
    "# a) We set axis = 1\n",
    "#    A dataframe has two axes: “axis 0” and “axis 1”.\n",
    "#    “axis 0” represents rows and “axis 1” represents columns.\n",
    "# b) We can also set Inplace = True.\n",
    "#    This means the changes would be made to the original dataframe.\n",
    "# Dropping the irrelevant columns i.e. Team and Weight\n",
    "# \n",
    "\n",
    "\n",
    "# And preview our resulting dataset\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "naAOHnkNsz-y"
   },
   "outputs": [],
   "source": [
    "# We can also drop multiple columns - drop height and weight columns\n",
    "# ---\n",
    "#\n",
    "\n",
    "# And preview our resulting dataset\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKkADApG7PQ-"
   },
   "source": [
    "##### <font color=\"blue\">Task 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-TlGDqmxO20t"
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# ---\n",
    "# We can also fix in-record & cross-datasets errors.\n",
    "# These kinds errors result from having two or more values in the same row\n",
    "# or across datasets contradicting with each other.\n",
    "# ---\n",
    "# Dataset = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "# Create a column that stores the sum of account_a and acoount_b\n",
    "\n",
    "\n",
    "\n",
    "# Previewing our resulting dataframe\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Zf0W-6fnvx0A"
   },
   "outputs": [],
   "source": [
    "# Create another column to tell us whether if the two columns match.\n",
    "# We will use the numpy library through use of np.\n",
    "# ---\n",
    "#\n",
    "\n",
    "\n",
    "# Previewing our resulting dataframe\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DGxUgJJ4wilM"
   },
   "outputs": [],
   "source": [
    "# Let's now select the records which don't match\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1CeKrayqxQuL"
   },
   "outputs": [],
   "source": [
    "# At this point we can do several things\n",
    "# 1. Correct the values,\n",
    "# 2. Drop/Delete the values,\n",
    "# 3. Or even decide to leave them as they are for certain reasons\n",
    "# ---\n",
    "# If we had a large dataset, we could get the no. of records using len(),\n",
    "# this would help us in our decision making process.\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQvS83K_PBJh"
   },
   "source": [
    "## 4. Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjklXwZLPBJw"
   },
   "source": [
    "#### <font color=\"blue\">Tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8VZ3JLQPBJy"
   },
   "source": [
    "##### <font color=\"blue\">Task 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dTlrpqh-PBJ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1\n",
    "# ---\n",
    "# Finding duplicate records\n",
    "# -> Duplicate records are repeated records in a dataset.\n",
    "# ---\n",
    "# Dataset url = http://bit.ly/NBABasketballDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "\n",
    "df_nba = pd.read_csv('http://bit.ly/NBABasketballDataset')\n",
    "\n",
    "# Again, we first explore our dataset by determining the shape of\n",
    "# our dataset (records/instances, columns/variables)\n",
    "# ---\n",
    "#\n",
    "df_nba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XRdHqs9p1L8t"
   },
   "outputs": [],
   "source": [
    "# We can then identify which observations are duplicates\n",
    "# through the duplicated() function and sum() to know how many\n",
    "# duplicate records there are.\n",
    "# Normally, duplicate records are dropped from the dataset.\n",
    "# But in our case we don't have any duplicate records.\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Kd6R2AB77A1e"
   },
   "outputs": [],
   "source": [
    "# Finding the no. of duplicates\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV883_Ft7M4c"
   },
   "source": [
    "##### <font color=\"blue\">Task 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jFMDOQUCPBKg"
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# ---\n",
    "# Dropping duplicate columns\n",
    "# ---\n",
    "# Dataset = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "\n",
    "# In our previous dataset, if there were duplicates we\n",
    "# could have dropped them through the use of the drop_duplicates() function\n",
    "# \n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hd0kybN7KEK"
   },
   "source": [
    "##### <font color=\"blue\">Task 3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1CNl8VL-PBKp"
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# ---\n",
    "# Dropping duplicates in a specific column\n",
    "# ---\n",
    "# Dataset url = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "#\n",
    "\n",
    "# We can also consider records with repeated variables/columns\n",
    "# as duplicates and deal with them. For example, we can\n",
    "# identify duplicates in our dataset based on country.\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "D33CBMxu5agd"
   },
   "outputs": [],
   "source": [
    "# Then dropping the duplicates \n",
    "# NB: We will create in a new dataframe object which will contain our unique dataframe\n",
    "# which won't have any duplicates.\n",
    "# ---\n",
    "#\n",
    "\n",
    "# Determining the size of our new dataset\n",
    "# We note that the two records were dropped from our original dataset\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7MfKNGePLVE"
   },
   "source": [
    "## 5. Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSyyvcJJPLVO"
   },
   "source": [
    "#### <font color=\"blue\">Tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWiBc-smPLVS"
   },
   "source": [
    "##### <font color=\"blue\">Task 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jz2zjwTZPLVT"
   },
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# ---\n",
    "# Finding records with missing data\n",
    "# ---\n",
    "# Dataset url = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "# OUR CODE GOES BELOW\n",
    "#\n",
    "\n",
    "# We can check if there is any missing values in the entire dataframe using the isnull()\n",
    "# NB: This method may not be the most convenient. Why?\n",
    "# ---\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7ZtDFohkKVab"
   },
   "outputs": [],
   "source": [
    "# We can also check for missing values in each column\n",
    "# NB: This method may not be the most convenient. Why?\n",
    "#\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "oY9LaH8_KcKl"
   },
   "outputs": [],
   "source": [
    "# We can check how many missing values there are across each variable/column \n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Y3RTlthxKgbu"
   },
   "outputs": [],
   "source": [
    "# We can also check to see if we have any missing values in the dataframe \n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3z3SDJZsKjz_"
   },
   "outputs": [],
   "source": [
    "# Lastly, We can also get a total count of missing values \n",
    "#\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_mlBg-TPLVe"
   },
   "source": [
    "##### <font color=\"blue\">Task 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QuNTnbSmPLVf"
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# ---\n",
    "# Dealing with the missing data\n",
    "# ---\n",
    "#\n",
    "\n",
    "# We can drop rows where all cells in that row is NA\n",
    "#\n",
    "# NB: We don't have these rows in our dataset\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2OWqJ6FJFmgw"
   },
   "outputs": [],
   "source": [
    "# We can also drop columns if they only contain missing values\n",
    "# NB: We don't have these rows in our dataset\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "PT4fmeWyFtYg"
   },
   "outputs": [],
   "source": [
    "# We can drop rows that contain less than five observations\n",
    "# NB: We don't have these rows in our dataset\n",
    "# ---\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "bfgdzPzNF35d"
   },
   "outputs": [],
   "source": [
    "# Lastly, we can also drop the missing observations\n",
    "# ---\n",
    "#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aaKxkwk7GGN"
   },
   "source": [
    "##### <font color=\"blue\">Task 3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dJf7iOj8rQrF"
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# ---\n",
    "# Flag missing values\n",
    "# ---\n",
    "# Dataset url = http://bit.ly/DataCleaningDataset\n",
    "# ---\n",
    "#\n",
    "\n",
    "# We can also fill in missing data with zeros \n",
    "# NB: First create a copy of the original dataframe\n",
    "# \n",
    "# ---\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8tAUAu98l-E6",
    "AdqLGpdH_867",
    "o39LEL0PmKJa",
    "BMXTATeJmOGX",
    "59SR9Kap7gMj",
    "WCk6jJA-7cpm",
    "F76wMqtH7Z6W",
    "OWcy51lCOuTv",
    "ONPG_rNpOuT8",
    "JBVRXQvY7WEB",
    "0ZXm4a9V7VFq",
    "ebaricL9O20B",
    "WWZ0GCbCO20L",
    "bjflp2aF7SUB",
    "NKkADApG7PQ-",
    "UQvS83K_PBJh",
    "CjklXwZLPBJw",
    "o8VZ3JLQPBJy",
    "SV883_Ft7M4c",
    "8Hd0kybN7KEK",
    "_7MfKNGePLVE",
    "tSyyvcJJPLVO",
    "gWiBc-smPLVS",
    "B_mlBg-TPLVe",
    "2aaKxkwk7GGN",
    "v5M3iGK8PZ3Y",
    "jnxNSUhdPZ3u",
    "0Z92GZUgPZ35"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
